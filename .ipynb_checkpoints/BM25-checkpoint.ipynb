{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "k1=0.4\n",
    "k3=0.4\n",
    "b=0.4\n",
    "query_list=[]\n",
    "file=open(\"query_list.txt\",\"r\").readlines()\n",
    "for item in file:\n",
    "    query_list.append(item.strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[]\n",
    "file=open(\"doc_list.txt\",\"r\").readlines()\n",
    "for item in file:\n",
    "    doc_list.append(item.strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset={}\n",
    "for query in query_list:\n",
    "    file=open(\"Query/\"+query,\"r\").readlines()\n",
    "    query_dataset.update({query:{}})\n",
    "    for item in file:\n",
    "        item=item.split()[:-1]\n",
    "        for word in item:\n",
    "            if word in query_dataset[query].keys():\n",
    "                query_dataset[query][word]+=1\n",
    "            else:\n",
    "                query_dataset[query].update({word:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "doc_dataset={}\n",
    "for query in query_list:\n",
    "    for word in query_dataset[query].keys():\n",
    "        if word not in dic:\n",
    "            dic.update({word:0})\n",
    "for doc in doc_list:\n",
    "    doc_dataset.update({doc:{}})\n",
    "    file=open(\"Document/\"+doc,\"r\").readlines()[3:]\n",
    "    for item in file:\n",
    "        item=item.split()[:-1]\n",
    "        for word in item:\n",
    "            if word not in dic:\n",
    "                dic.update({word:0})\n",
    "            if word in doc_dataset[doc].keys():\n",
    "                doc_dataset[doc][word]+=1\n",
    "            else:\n",
    "                doc_dataset[doc].update({word:1})\n",
    "for doc in doc_list:\n",
    "    for word in dic.keys():\n",
    "        if word not in doc_dataset[doc].keys():\n",
    "            doc_dataset[doc].update({word:0})\n",
    "        else:\n",
    "            dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.51920529801325\n"
     ]
    }
   ],
   "source": [
    "doc_len={}\n",
    "doc_num=len(doc_list)\n",
    "dic_len=len(dic)\n",
    "for doc in doc_list:\n",
    "    doc_len.update({doc:0})\n",
    "    sum=0\n",
    "    for word in dic.keys():\n",
    "        sum+=doc_dataset[doc][word]\n",
    "    doc_len[doc]=sum\n",
    "s=0\n",
    "for doc in doc_list:\n",
    "    s=doc_len[doc]+s\n",
    "doc_avglen=s/doc_num\n",
    "print(doc_avglen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_len={}\n",
    "for query in query_list:\n",
    "    sum=0\n",
    "    query_len.update({query:0})\n",
    "    for word in query_dataset[query].keys():\n",
    "        sum+=query_dataset[query][word]\n",
    "    query_len[query]=sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ans={}\n",
    "for query in query_list:\n",
    "    query_ans.update({query:{}})\n",
    "    for doc in doc_list:\n",
    "        ans=0\n",
    "        a=0\n",
    "        c=0\n",
    "        d=0\n",
    "        f=0\n",
    "        for word in query_dataset[query].keys():\n",
    "            a=(doc_num-dic[word]+0.5)/(dic[word]+0.5)\n",
    "            a=math.log(a)\n",
    "            c=k3+1\n",
    "            c=c*query_dataset[query][word]\n",
    "            c=c/(k3+query_dataset[query][word])\n",
    "            d=(k1+1)*doc_dataset[doc][word]\n",
    "            f=1-b\n",
    "            f=f+(b*doc_len[doc]/doc_avglen)\n",
    "            f=f*k1+doc_dataset[doc][word]\n",
    "            f=d/f\n",
    "            ans+=f*a*c\n",
    "        query_ans[query].update({doc:ans})\n",
    "f = open(\"submission.txt\", \"w\")\n",
    "f.write(\"Query,RetrievedDocuments\\n\")\n",
    "for query in query_list:\n",
    "    f.write(query+\",\")\n",
    "    final0=sorted(query_ans[query].items(),key=lambda x:x[1],reverse=True)\n",
    "    for item in final0:\n",
    "        f.write(item[0]+\" \")\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
